{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06be0144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports needed for the notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor   \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import RepeatedKFold, GroupKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import cKDTree\n",
    "from tqdm import trange\n",
    "import skgstat as skg\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bee7ac",
   "metadata": {},
   "source": [
    "\n",
    "## Load data\n",
    "Load the Airbnb dataset from `airbnb_clean.csv` for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe34e5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/airbnb/airbnb_clean.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load the cleaned Airbnb dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../data/airbnb/airbnb_clean.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Features: all columns except 'price'\u001b[39;00m\n\u001b[32m      8\u001b[39m X = df.drop([\u001b[33m'\u001b[39m\u001b[33mprice\u001b[39m\u001b[33m'\u001b[39m], axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/airbnb/airbnb_clean.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the cleaned Airbnb dataset\n",
    "df = pd.read_csv('../data/airbnb/airbnb_clean.csv')\n",
    "\n",
    "# Features: all columns except 'price'\n",
    "X = df.drop(['price'], axis=1)\n",
    "\n",
    "# Target: price\n",
    "y = df['price'].values\n",
    "\n",
    "# Coordinates for spatial CV (assumes columns are named 'longitude' and 'latitude')\n",
    "coords = df[['longitude', 'latitude']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968c5fb1",
   "metadata": {},
   "source": [
    "\n",
    "## Pipeline & models\n",
    "- **Preprocessing:** median-impute + scale numeric; most-frequent-impute + one-hot categorical.  \n",
    "- **Model:** **Ridge** regression (fast). You can switch to **RandomForestRegressor** below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ce954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "num_tf = Pipeline([(\"scaler\", StandardScaler())])\n",
    "\n",
    "# All features are numeric, so use all columns\n",
    "preprocess = ColumnTransformer([(\"num\", num_tf, X.columns.tolist())], remainder=\"drop\")\n",
    "\n",
    "# Choose model here\n",
    "rf = RandomForestRegressor(n_estimators=400, min_samples_leaf=2, n_jobs=-1, random_state=42)\n",
    "rf = SGDRegressor(random_state=42)\n",
    "\n",
    "# Active pipeline (Random Forest)\n",
    "pipe = Pipeline([(\"prep\", preprocess), (\"model\", rf)])\n",
    "\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c798baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After loading, update numeric_cols and rebuild pipeline\n",
    "\n",
    "numeric_cols = X.columns.tolist()\n",
    "\n",
    "preprocess = ColumnTransformer([(\"num\", num_tf, numeric_cols)], remainder=\"drop\")\n",
    "\n",
    "pipe = Pipeline([(\"prep\", preprocess), (\"model\", rf)])\n",
    "\n",
    "print(\"Pipeline rebuilt with columns:\", numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96eab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_blocks(\n",
    "    coords: np.ndarray,\n",
    "    method: str = 'grid',\n",
    "    n_blocks: int = 5,\n",
    "    grid_aspect: str = 'auto',\n",
    "    random_state: int = 42,\n",
    "    **kwargs\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Assign spatial blocks to coordinates using either a grid or k-means clustering.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coords : np.ndarray\n",
    "        Array of shape (n_samples, 2) with spatial coordinates.\n",
    "    method : str, optional\n",
    "        Block assignment method: 'grid' or 'kmeans'. Default is 'grid'.\n",
    "    n_blocks : int, optional\n",
    "        Number of blocks to assign. For 'grid', will use closest square grid.\n",
    "    grid_aspect : str, optional\n",
    "        'auto' for square grid, or 'rect' for rectangular grid (future extension).\n",
    "    random_state : int, optional\n",
    "        Random seed for k-means. Default is 42.\n",
    "    **kwargs\n",
    "        Additional arguments passed to KMeans or future grid options.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    groups : np.ndarray\n",
    "        Array of group/block assignments for each coordinate.\n",
    "    block_info : dict\n",
    "        Dictionary with grid metadata if method='grid', clustering metadata if method='kmeans'.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If method is not recognized or input is invalid.\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if not isinstance(coords, np.ndarray):\n",
    "        raise TypeError(\"coords must be a numpy array\")\n",
    "    if coords.ndim != 2 or coords.shape[1] != 2:\n",
    "        raise ValueError(\"coords must be of shape (n_samples, 2)\")\n",
    "    if n_blocks < 1:\n",
    "        raise ValueError(\"n_blocks must be >= 1\")\n",
    "\n",
    "    if method == 'grid':\n",
    "        # Square grid: find closest integer for cells per side\n",
    "        cells_per_side = int(np.ceil(np.sqrt(n_blocks)))\n",
    "        mins = coords.min(axis=0)\n",
    "        maxs = coords.max(axis=0)\n",
    "        span = np.maximum(maxs - mins, 1e-9)\n",
    "        cell = span / cells_per_side\n",
    "        ij = np.floor((coords - mins) / cell).astype(int)\n",
    "        # Clip indices to grid bounds\n",
    "        ij = np.clip(ij, 0, cells_per_side - 1)\n",
    "        # Encode group as integer\n",
    "        groups = ij[:, 0] * cells_per_side + ij[:, 1]\n",
    "        block_info = {\n",
    "            'mins': mins,\n",
    "            'maxs': maxs,\n",
    "            'cell': cell,\n",
    "            'cells_per_side': cells_per_side,\n",
    "            'n_blocks': cells_per_side ** 2,\n",
    "            'method': 'grid'\n",
    "        }\n",
    "        return groups, block_info\n",
    "\n",
    "    elif method == 'kmeans':\n",
    "        if n_blocks > coords.shape[0]:\n",
    "            raise ValueError(\"n_blocks cannot exceed number of samples for kmeans\")\n",
    "        kmeans = KMeans(n_init='auto', n_clusters=n_blocks, random_state=random_state, **kwargs)\n",
    "        groups = kmeans.fit_predict(coords)\n",
    "        block_info = {\n",
    "            'n_blocks': n_blocks,\n",
    "            'method': 'kmeans',\n",
    "            'inertia': kmeans.inertia_\n",
    "        }\n",
    "        return groups, block_info\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}. Use 'grid' or 'kmeans'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7765d139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_partition(coords: np.ndarray, groups: np.ndarray, block_info: dict = None,\n",
    "                  figsize: tuple = (8, 6), point_size: int = 10, cmap: str = 'tab20',\n",
    "                  show_legend: bool = True, ax=None, title: str = None, max_groups: int = 20) -> None:\n",
    "    \"\"\"\n",
    "    Visualize any spatial block/group partition (grid, k-means, etc), limiting the number of groups plotted.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coords : np.ndarray\n",
    "        Array of shape (n_samples, 2) with spatial coordinates.\n",
    "    groups : np.ndarray\n",
    "        Array of group/block assignments for each coordinate.\n",
    "    block_info : dict, optional\n",
    "        Dictionary with grid or clustering metadata. If grid, draws grid lines.\n",
    "    figsize : tuple, optional\n",
    "        Figure size for the plot. Default is (8, 6).\n",
    "    point_size : int, optional\n",
    "        Size of scatter plot points. Default is 10.\n",
    "    cmap : str, optional\n",
    "        Colormap for group coloring. Default is 'tab20'.\n",
    "    show_legend : bool, optional\n",
    "        Whether to show legend for groups. Default is True.\n",
    "    ax : matplotlib.axes.Axes, optional\n",
    "        Existing matplotlib axis to plot on. If None, creates new figure.\n",
    "    title : str, optional\n",
    "        Title for the plot. If None, uses block_info['method'] if available.\n",
    "    max_groups : int, optional\n",
    "        Maximum number of unique groups to plot. Others are ignored. Default is 20.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    unique_groups = np.unique(groups)\n",
    "    if len(unique_groups) > max_groups:\n",
    "        # Only plot the first max_groups groups\n",
    "        selected_groups = unique_groups[:max_groups]\n",
    "        mask = np.isin(groups, selected_groups)\n",
    "        coords = coords[mask]\n",
    "        groups = groups[mask]\n",
    "        legend_note = f\"(showing first {max_groups} groups)\"\n",
    "    else:\n",
    "        legend_note = None\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    scatter = ax.scatter(coords[:, 0], coords[:, 1], c=groups, cmap=cmap, s=point_size, alpha=0.8, edgecolor='none')\n",
    "\n",
    "    # Draw grid lines if grid partition\n",
    "    if block_info is not None and block_info.get('method') == 'grid':\n",
    "        mins = block_info['mins']\n",
    "        cell = block_info['cell']\n",
    "        cells_per_side = block_info['cells_per_side']\n",
    "        for i in trange(1, cells_per_side):\n",
    "            x = mins[0] + i * cell[0]\n",
    "            ax.axvline(x, color='gray', linestyle='--', linewidth=0.7, alpha=0.7)\n",
    "            y = mins[1] + i * cell[1]\n",
    "            ax.axhline(y, color='gray', linestyle='--', linewidth=0.7, alpha=0.7)\n",
    "\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    elif block_info is not None and 'method' in block_info:\n",
    "        ax.set_title(f\"Partition ({block_info['method'].capitalize()} Blocks)\")\n",
    "    else:\n",
    "        ax.set_title('Spatial Partition (Blocks)')\n",
    "\n",
    "    if show_legend:\n",
    "        import matplotlib.patches as mpatches\n",
    "        unique_groups = np.unique(groups)\n",
    "        colors = [scatter.cmap(scatter.norm(g)) for g in unique_groups]\n",
    "        handles = [mpatches.Patch(color=col, label=f'Block {g}') for g, col in zip(unique_groups, colors)]\n",
    "        ax.legend(handles=handles, title='Block Group', bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize='small')\n",
    "\n",
    "\n",
    "def plot_buffered_cv_partitions(coords, X, y, groups, buffer_m, max_blocks=20, ncols=4, point_size=5, figsize_scale=5):\n",
    "    \"\"\"\n",
    "    Modular visualization of buffered spatial CV partitions for any block assignment.\n",
    "    Shows train (buffered), excluded by buffer, and test fold for each block.\n",
    "    Parameters:\n",
    "        coords: np.ndarray, shape (n_samples, 2)\n",
    "        X: pd.DataFrame or np.ndarray\n",
    "        y: np.ndarray\n",
    "        groups: np.ndarray, block assignments\n",
    "        buffer_m: float, buffer radius in same units as coords\n",
    "        max_blocks: int, max number of blocks to plot\n",
    "        ncols: int, number of columns in subplot grid\n",
    "        point_size: int, size for all points\n",
    "        figsize_scale: int, scale for figure size\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import GroupKFold\n",
    "    from scipy.spatial import cKDTree\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    unique_blocks = np.unique(groups)\n",
    "    n_blocks = min(len(unique_blocks), max_blocks)\n",
    "    nrows = int(np.ceil(n_blocks / ncols))\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(figsize_scale*ncols, figsize_scale*nrows), squeeze=False)\n",
    "    \n",
    "    gkf = GroupKFold(n_splits=n_blocks)\n",
    "    tree = cKDTree(coords)\n",
    "    \n",
    "    for i, (tr_all, te) in enumerate(gkf.split(X, y, groups=groups)):\n",
    "        if i >= n_blocks:\n",
    "            break\n",
    "        neigh_lists = tree.query_ball_point(coords[te], r=buffer_m)\n",
    "        banned = np.unique(np.concatenate(neigh_lists)) if len(neigh_lists) else np.array([], dtype=int)\n",
    "        tr_buffered = np.setdiff1d(tr_all, banned, assume_unique=False)\n",
    "        ax = axes[i // ncols][i % ncols]\n",
    "        ax.scatter(coords[tr_buffered,0], coords[tr_buffered,1], c='blue', s=point_size, label='Train (buffered)')\n",
    "        ax.scatter(coords[banned,0], coords[banned,1], c='orange', s=point_size, label='Excluded by buffer')\n",
    "        ax.scatter(coords[te,0], coords[te,1], c='red', s=point_size, label='Test fold')\n",
    "        ax.set_title(f'Block {i+1} (Buffer={buffer_m:.0f} m)')\n",
    "        ax.set_xlabel('Longitude')\n",
    "        ax.set_ylabel('Latitude')\n",
    "        ax.legend(loc='best', fontsize='small')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for j in range(i+1, nrows*ncols):\n",
    "        axes[j // ncols][j % ncols].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_buffered_loo_iteration(coords, buffer_m, test_idx=None, ax=None, point_size=10):\n",
    "    \"\"\"\n",
    "    Plot a single iteration of buffered leave-one-out CV.\n",
    "    Shows: test point, training points (outside buffer), excluded points (inside buffer).\n",
    "    \"\"\"\n",
    "    n = coords.shape[0]\n",
    "    if test_idx is None:\n",
    "        test_idx = random.randint(0, n-1)\n",
    "    tree = cKDTree(coords)\n",
    "    banned = tree.query_ball_point(coords[test_idx], r=buffer_m)\n",
    "    banned = np.array(banned)\n",
    "    tr = np.setdiff1d(np.arange(n), banned, assume_unique=True)\n",
    "    \n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize=(7, 6))\n",
    "    \n",
    "    # Plot training points (outside buffer)\n",
    "    ax.scatter(coords[tr,0], coords[tr,1], c='blue', s=point_size, label='Train (outside buffer)', alpha=0.7)\n",
    "    # Plot excluded points (inside buffer, not test)\n",
    "    excluded = np.setdiff1d(banned, [test_idx], assume_unique=True)\n",
    "    ax.scatter(coords[excluded,0], coords[excluded,1], c='orange', s=point_size, label='Excluded by buffer', alpha=0.7)\n",
    "    # Plot test point\n",
    "    ax.scatter(coords[test_idx,0], coords[test_idx,1], c='red', s=point_size*2, label='Test point', edgecolor='black', linewidth=1.5, zorder=10)\n",
    "    \n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title(f'Buffered LOO CV (Buffer={buffer_m:.0f} m), Test idx={test_idx}')\n",
    "    ax.legend(loc='best', fontsize='small')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4379723e",
   "metadata": {},
   "source": [
    "\n",
    "## Cross-validation utilities\n",
    "- **Random CV:** Repeated K-fold.  \n",
    "- **Spatial blocks:** GroupKFold on grid cells.  \n",
    "- **Buffered spatial CV:** additionally drop training points within *buffer* meters of test fold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3906a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(a,b): \n",
    "    return float(np.sqrt(mean_squared_error(a,b)))\n",
    "\n",
    "\n",
    "def random_cv_scores(pipe, X, y, n_splits=5, n_repeats=3, seed=123):\n",
    "    rkf = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=seed)\n",
    "    scores = []\n",
    "    for tr, te in rkf.split(X):\n",
    "        pipe.fit(X.iloc[tr], y[tr])\n",
    "        yp = pipe.predict(X.iloc[te])\n",
    "        scores.append(rmse(y[te], yp))\n",
    "    return np.array(scores)\n",
    "\n",
    "def spatial_cv_scores(pipe, X, y, groups, n_splits=5):\n",
    "    uniq = np.unique(groups)\n",
    "    current_n_splits = min(n_splits, len(uniq)) if len(uniq) >= 2 else 2\n",
    "    gkf = GroupKFold(n_splits=current_n_splits)\n",
    "    scores = []\n",
    "    for tr, te in gkf.split(X, y, groups=groups):\n",
    "        pipe.fit(X.iloc[tr], y[tr])\n",
    "        yp = pipe.predict(X.iloc[te])\n",
    "        scores.append(rmse(y[te], yp))\n",
    "    return np.array(scores)\n",
    "\n",
    "\n",
    "def buffered_spatial_cv_scores(pipe, X, y, coords, groups, buffer_m, n_splits=5):\n",
    "    tree = cKDTree(coords)\n",
    "    uniq = np.unique(groups)\n",
    "    current_n_splits = min(n_splits, len(uniq)) if len(uniq) >= 2 else 2\n",
    "    gkf = GroupKFold(n_splits=current_n_splits)\n",
    "    scores = []\n",
    "    for tr_all, te in gkf.split(X, y, groups=groups):\n",
    "        # drop training points within buffer of any test point\n",
    "        neigh_lists = tree.query_ball_point(coords[te], r=buffer_m)\n",
    "        banned = np.unique(np.concatenate(neigh_lists)) if len(neigh_lists) else np.array([], dtype=int)\n",
    "        tr = np.setdiff1d(tr_all, banned, assume_unique=False)\n",
    "        if tr.size < 20:  # fallback if too aggressive\n",
    "            tr = tr_all\n",
    "        pipe.fit(X.iloc[tr], y[tr])\n",
    "        yp = pipe.predict(X.iloc[te])\n",
    "        scores.append(rmse(y[te], yp))\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b38b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_buffer(coords, k=6):\n",
    "    \"\"\"Compute buffer distance as the median distance to the k-th nearest neighbor (default k=6).\"\"\"\n",
    "    from scipy.spatial import cKDTree\n",
    "    tree = cKDTree(coords)\n",
    "    dists, _ = tree.query(coords, k=k)\n",
    "    buffer_m = float(np.median(dists[:, k-1]))\n",
    "    return buffer_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e15501",
   "metadata": {},
   "source": [
    "\n",
    "## Run the evaluations\n",
    "This will compute RMSE for:\n",
    "- Random CV,\n",
    "- Spatial block CV (5 folds),\n",
    "- Buffered Spatial CV (buffer ≈ median 5th-NN distance in meters).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6596f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_blocks = 10 # number of spatial blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa22b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups, grid_info = assign_blocks(coords, method=\"grid\", n_blocks=n_blocks)\n",
    "\n",
    "plot_partition(coords, groups, block_info=grid_info,\n",
    "               figsize=(8, 6), point_size=10, cmap='tab20', show_legend=True,\n",
    "               title='Spatial Blocks (Grid Groups)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c9d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_kmeans, kmeans_info = assign_blocks(coords, method='kmeans', n_blocks=n_blocks)\n",
    "\n",
    "plot_partition(coords, groups_kmeans, block_info=kmeans_info,\n",
    "               figsize=(8, 6), point_size=10, cmap='tab20', show_legend=True,\n",
    "               title='Spatial Blocks (K-means Groups)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cbb649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "plot_buffered_cv_partitions(coords, X, y, groups, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8523f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_buffered_cv_partitions(coords, X, y, groups_kmeans, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46740eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute empirical semivariogram and extract spatial range as buffer distance\n",
    "V = skg.Variogram(\n",
    "    coordinates=coords,\n",
    "    values=y,\n",
    "    model='exponential',\n",
    "    n_lags=16,\n",
    "    maxlag='median',\n",
    "    use_nugget=True,\n",
    "    estimator='cressie')\n",
    " \n",
    "V.plot()\n",
    "\n",
    "print(f\"Buffer distance estimated from semivariogram range: {V.parameters[2]:.0f} meters\")\n",
    "\n",
    "semivariogram_buffer_m = V.parameters[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c499a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "buffer_m = semivariogram_buffer_m\n",
    "\n",
    "rand_scores = random_cv_scores(pipe, X, y, n_splits=n_splits, seed=123)\n",
    "spat_scores = spatial_cv_scores(pipe, X, y, groups, n_splits=n_splits)\n",
    "buf_scores = buffered_spatial_cv_scores(pipe, X, y, coords, groups, buffer_m=buffer_m, n_splits=n_splits)\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"CV\": [\"Random\", \"Spatial blocks\", f\"Buffered spatial (~{buffer_m:.0f} m)\"],\n",
    "    \"RMSE_mean\": [rand_scores.mean(), spat_scores.mean(), buf_scores.mean()],\n",
    "    \"n_folds\":   [rand_scores.size,   spat_scores.size,   buf_scores.size],\n",
    "})\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d4d5a5",
   "metadata": {},
   "source": [
    "## Buffered Leave-One-Out Spatial Cross-Validation\n",
    "This method tests model generalization at individual locations, but with strict spatial independence: for each test point, all training points within a buffer distance are excluded. This is especially useful for dense spatial samples and helps avoid information leakage due to spatial autocorrelation.\n",
    "\n",
    "Below is an implementation for the Airbnb dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751b952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffered_loo_cv_scores(pipe, X, y, coords, buffer_m, max_iter=None):\n",
    "    \"\"\"\n",
    "    Buffered Leave-One-Out Spatial Cross-Validation.\n",
    "    For each observation, use it as the test set, and exclude all training points within buffer_m of the test point.\n",
    "    Returns array of RMSEs (one per test point).\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(y) if max_iter is None else min(len(y), max_iter)\n",
    "    tree = cKDTree(coords)\n",
    "    scores = []\n",
    "\n",
    "    for i in trange(n):\n",
    "        banned = tree.query_ball_point(coords[i], r=buffer_m)\n",
    "        tr = np.setdiff1d(np.arange(n), banned, assume_unique=False)\n",
    "        \n",
    "        pipe.fit(X.iloc[tr], y[tr])\n",
    "        yp = pipe.predict(X.iloc[[i]])\n",
    "        scores.append(rmse(y[[i]], yp))\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc69d397",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_buffered_loo_iteration(coords, buffer_m=semivariogram_buffer_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e871199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to summary table\n",
    "buffered_loo_scores = buffered_loo_cv_scores(pipe, X, y, coords, buffer_m=semivariogram_buffer_m)\n",
    "loo_scores = buffered_loo_cv_scores(pipe, X, y, coords, buffer_m=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f98a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    \"CV\": [\n",
    "        \"Random\",\n",
    "        \"LOO (no buffer)\",\n",
    "        f\"Buffered LOO (~{buffer_m:.0f} m)\"\n",
    "    ],\n",
    "    \"RMSE_mean\": [\n",
    "        rand_scores.mean(),\n",
    "        loo_scores.mean(),\n",
    "        buffered_loo_scores.mean()\n",
    "    ],\n",
    "    \"RMSE_var\": [\n",
    "        rand_scores.var(),\n",
    "        loo_scores.var(),\n",
    "        buffered_loo_scores.var()\n",
    "    ],\n",
    "    \"n_folds\": [\n",
    "        rand_scores.size,\n",
    "        loo_scores.size,\n",
    "        buffered_loo_scores.size\n",
    "    ],\n",
    "})\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11357cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da06c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b5085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
